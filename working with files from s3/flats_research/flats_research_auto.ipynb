{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import boto3\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import ACCESS_KEY,SECRET_KEY,TOKEN,FOLDER,FOLDER_ID,BUCKET_NAME,BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_ZONE = os.getenv(\"TIME_ZONE\", \"Europe/Moscow\") #настройка функции\n",
    "TEMP_FILENAME = \"temp_file\"\n",
    "\n",
    "def get_now_datetime_str(): # получаем актуальное время\n",
    "    time_zone = os.getenv(\"TIME_ZONE\", \"Europe/Moscow\") # меняем таймзону на московскую\n",
    "    now = datetime.datetime.now(pytz.timezone(time_zone))    \n",
    "    yesterday = now - datetime.timedelta(days=1) #нужна вчерашняя дата так как данные за прошлый день\n",
    "    last_month_data = now - relativedelta(month=1)\n",
    "    return {'key_parquet': yesterday.strftime('year=%Y/month=%m/%d.parquet'),\n",
    "            'key': yesterday.strftime('year=%Y/month=%m/%d.csv'),\n",
    "            'key_month': yesterday.strftime('year=%Y/month=%m.csv'),\n",
    "            'now':now.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'yesterday_data':yesterday.strftime('%Y-%m-%d'),\n",
    "            'yesterday':yesterday.strftime('%Y-%m-%d %H:%M:%S'), \n",
    "            'year':yesterday.strftime('%Y'),\n",
    "            'month':yesterday.strftime('%m'),\n",
    "            'day':yesterday.strftime('%d'),\n",
    "            'last_month_data':last_month_data.strftime('%Y-%m-%d')\n",
    "            }\n",
    "\n",
    "def create_query(): #функция создает новый запрос и возвращает id для запроса результата\n",
    "    body = {\n",
    "        \"name\":query_name, \n",
    "        \"TYPE\":\"ANALYTICS\", \n",
    "        \"text\":query_text, \n",
    "        \"description\":query_description\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f'https://api.yandex-query.cloud.yandex.net/api/fq/v1/queries?project={FOLDER_ID}',\n",
    "        headers=headers,\n",
    "        json=body\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"id\"]\n",
    "    return f' Code: {response},  text: {response.text}'\n",
    "\n",
    "\n",
    "def get_request(offset): # фунция возвращает ответ запроса. Максимум 1000 строк.\n",
    "    offset = offset\n",
    "    get_query_results_url = f'https://api.yandex-query.cloud.yandex.net/api/fq/v1/queries/{request_id}/results/0?project={FOLDER_ID}&offset={str(offset)}&limit=1000'\n",
    "    response = requests.get(\n",
    "        get_query_results_url,\n",
    "        headers = headers\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def if_cell_is_list(cell): # функция участвует в преобразовании данных при создании файла\n",
    "    if isinstance(cell, list):\n",
    "        if len(cell) == 0:\n",
    "            return ''\n",
    "        else: \n",
    "            return cell[0]\n",
    "    else:\n",
    "        return cell\n",
    "\n",
    "def write_temp_file():\n",
    "    offset = 0\n",
    "    response = get_request(offset) #запрашиваем данные запроса\n",
    "    columns = [rows['name'] for rows in response.json()['columns']] #выделяем названия столбцов\n",
    "    special_str = \"\"\n",
    "    for j in columns:\n",
    "        special_str = f\"{special_str}{str(j)},\"\n",
    "    temp_file = open(TEMP_FILENAME, 'w')\n",
    "    temp_file.write(special_str[:-1]+'\\n')\n",
    "\n",
    "def write_temp_file():\n",
    "    offset = 0\n",
    "    response = get_request(offset) #запрашиваем данные запроса\n",
    "    columns = [rows['name'] for rows in response.json()['columns']] #выделяем названия столбцов\n",
    "    special_str = \"\"\n",
    "    for j in columns:\n",
    "        special_str = f\"{special_str}{str(j)},\"\n",
    "    temp_file = open(TEMP_FILENAME, 'w', encoding='utf-8')\n",
    "    temp_file.write(special_str[:-1]+'\\n')\n",
    "\n",
    "    while response.status_code == 200 and len(response.json()['rows']) != 0:  #Цикл делает запросы по 10000, пока не кончатся данные\n",
    "        response = get_request(offset)\n",
    "        response_rows = response.json()['rows']\n",
    "        rows = [[if_cell_is_list(cell) for cell in row] for row in response_rows]  #Преобразуются строки\n",
    "        # Открывает созданный файл и добавляет в него строки\n",
    "        for row in rows:\n",
    "            special_str = ','.join(\"'{0}'\".format(i.replace(\"'\", \"\"))  if isinstance(i, str) else str(i) for i in row)\n",
    "            temp_file.write(special_str+'\\n') \n",
    "        offset +=1000 # увеличивает смещение\n",
    "\n",
    "def get_s3_instance(): # функция создает соединение\n",
    "    session = boto3.session.Session()\n",
    "    return session.client(\n",
    "        aws_access_key_id=ACCESS_KEY,\n",
    "        aws_secret_access_key=SECRET_KEY,\n",
    "        service_name='s3',\n",
    "        endpoint_url='https://storage.yandexcloud.net'\n",
    "    )\n",
    "\n",
    "def upload_dump_to_s3(): # функция выгружает данные в s3\n",
    "    get_s3_instance().upload_file(\n",
    "        Filename=TEMP_FILENAME,\n",
    "        Bucket=BUCKET_NAME,\n",
    "        Key=key\n",
    "    )\n",
    "\n",
    "def remove_temp_files(): #функция удаляет временный файл\n",
    "    os.remove(TEMP_FILENAME)\n",
    "\n",
    "s3 = get_s3_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date = datetime.datetime.strptime('2024-10-11','%Y-%m-%d').date()\n",
    "end_date = datetime.datetime.strptime('2024-10-11','%Y-%m-%d').date()\n",
    "dates_pd = pd.DataFrame({\n",
    "        'date_range': pd.date_range(start=start_date, end=end_date),\n",
    "        'date_key': pd.date_range(start=start_date, end=end_date).strftime('year=%Y/month=%m/%d.csv'),\n",
    "        'date_key_parquet': pd.date_range(start=start_date, end=end_date).strftime('year=%Y/month=%m/%d.parquet'),\n",
    "        'year': pd.date_range(start=start_date, end=end_date).strftime('%Y'),\n",
    "        'month': pd.date_range(start=start_date, end=end_date).strftime('%m'),\n",
    "        'day': pd.date_range(start=start_date, end=end_date).strftime('%d'),\n",
    "        'date_key_folder': pd.date_range(start=start_date, end=end_date).strftime('year=%Y/month=%m')\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key_parquet': 'year=2024/month=11/13.parquet',\n",
       " 'key': 'year=2024/month=11/13.csv',\n",
       " 'key_month': 'year=2024/month=11.csv',\n",
       " 'now': '2024-11-14 12:42:18',\n",
       " 'yesterday_data': '2024-11-13',\n",
       " 'yesterday': '2024-11-13 12:42:18',\n",
       " 'year': '2024',\n",
       " 'month': '11',\n",
       " 'day': '13',\n",
       " 'last_month_data': '2024-01-14'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_now_datetime_str(): # получаем актуальное время\n",
    "    time_zone = os.getenv(\"TIME_ZONE\", \"Europe/Moscow\") # меняем таймзону на московскую\n",
    "    now = datetime.datetime.now(pytz.timezone(time_zone))    \n",
    "    yesterday = now - datetime.timedelta(days=1) #нужна вчерашняя дата так как данные за прошлый день\n",
    "    last_month_data = now - relativedelta(month=1)\n",
    "    return {'key_parquet': yesterday.strftime('year=%Y/month=%m/%d.parquet'),\n",
    "            'key': yesterday.strftime('year=%Y/month=%m/%d.csv'),\n",
    "            'key_month': yesterday.strftime('year=%Y/month=%m.csv'),\n",
    "            'now':now.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'yesterday_data':yesterday.strftime('%Y-%m-%d'),\n",
    "            'yesterday':yesterday.strftime('%Y-%m-%d %H:%M:%S'), \n",
    "            'year':yesterday.strftime('%Y'),\n",
    "            'month':yesterday.strftime('%m'),\n",
    "            'day':yesterday.strftime('%d'),\n",
    "            'last_month_data':last_month_data.strftime('%Y-%m-%d')\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "get_now_datetime_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(local_download_path) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# создается новая папка, если ее нет\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(local_download_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 72\u001b[0m     \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBUCKET_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mFilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_download_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m flats_st_partner_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_download_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Объеденяем flats_st_partner и flats_dir_partner\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\inject.py:192\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\transfer.py:406\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[1;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[0;32m    402\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[0;32m    403\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[0;32m    404\u001b[0m )\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\tasks.py:269\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[1;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator\u001b[38;5;241m.\u001b[39mset_status_to_running()\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;66;03m# transfer.\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\download.py:354\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[1;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m    downloading streams\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;66;03m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;66;03m# user.\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprovide_transfer_size(\n\u001b[0;32m    360\u001b[0m         response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContentLength\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    363\u001b[0m download_output_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_download_output_manager_cls(\n\u001b[0;32m    364\u001b[0m     transfer_future, osutil\n\u001b[0;32m    365\u001b[0m )(osutil, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator, io_executor)\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\botocore\\client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Boris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\botocore\\client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"dwh-asgard\"\n",
    "FOLDER = 'flats_dir_partner'\n",
    "s3_file_name = f\"{FOLDER}/flats_dir_partner.csv\"\n",
    "s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:1])\n",
    "\n",
    "path_on_pc = 'D:/s3'\n",
    "local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "if os.path.isfile(local_download_path) is False:\n",
    "# создается новая папка, если ее нет\n",
    "    os.makedirs(local_download_folder, exist_ok=True)\n",
    "    s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "BUCKET_NAME = \"dwh-asgard\"\n",
    "FOLDER = 'entries_installation_points_dir_partner'\n",
    "s3_file_name = f\"{FOLDER}/entries_installation_points_dir_partner.csv\"\n",
    "s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:1])\n",
    "\n",
    "path_on_pc = 'D:/s3'\n",
    "local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "if os.path.isfile(local_download_path) is False:\n",
    "# создается новая папка, если ее нет\n",
    "    os.makedirs(local_download_folder, exist_ok=True)\n",
    "    s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "entries_installation_points_dir_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "for i in range(0,dates_pd.shape[0]):\n",
    "    year = dates_pd.loc[i,['year']].values[0]\n",
    "    month = dates_pd.loc[i,['month']].values[0]\n",
    "    day = dates_pd.loc[i,['day']].values[0]\n",
    "    \n",
    "    # Подгрузка flats_dir_partner\n",
    "\n",
    "    BUCKET_NAME = \"dwh-asgard\"\n",
    "    FOLDER = 'flats_dir_partner'\n",
    "    s3_file_name = f\"{FOLDER}/flats_dir_partner.csv\"\n",
    "    s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:1])\n",
    "\n",
    "    path_on_pc = 'D:/s3'\n",
    "    local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "    local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "    if os.path.isfile(local_download_path) is False:\n",
    "    # создается новая папка, если ее нет\n",
    "        os.makedirs(local_download_folder, exist_ok=True)\n",
    "        s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "    flats_dir_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "    # Подгрузка flats_st_partner\n",
    "\n",
    "\n",
    "\n",
    "    BUCKET_NAME = \"dwh-asgard\"\n",
    "    FOLDER = 'flats_st_partner'\n",
    "\n",
    "    key = f\"year={int(year)}/month={int(month)}/{int(day)}.csv\"\n",
    "    s3_file_name = f\"{FOLDER}/{key}\"\n",
    "    s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:3])\n",
    "\n",
    "    path_on_pc = 'D:/s3'\n",
    "    local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "    local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "    if os.path.isfile(local_download_path) is False:\n",
    "    # создается новая папка, если ее нет\n",
    "        os.makedirs(local_download_folder, exist_ok=True)\n",
    "        s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "    flats_st_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "    # Объеденяем flats_st_partner и flats_dir_partner\n",
    "\n",
    "    flats_st_partner_df = flats_st_partner_df.merge(\n",
    "        flats_dir_partner_df[['flat_uuid','address_uuid']],\n",
    "        on='flat_uuid',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "\n",
    "    # Подгрузка entries_installation_points_dir_partner\n",
    "\n",
    "    BUCKET_NAME = \"dwh-asgard\"\n",
    "    FOLDER = 'entries_installation_points_dir_partner'\n",
    "    s3_file_name = f\"{FOLDER}/entries_installation_points_dir_partner.csv\"\n",
    "    s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:1])\n",
    "\n",
    "    path_on_pc = 'D:/s3'\n",
    "    local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "    local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "    if os.path.isfile(local_download_path) is False:\n",
    "    # создается новая папка, если ее нет\n",
    "        os.makedirs(local_download_folder, exist_ok=True)\n",
    "        s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "    entries_installation_points_dir_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "    # Подгрузка installation_point_st_partner\n",
    "\n",
    "    BUCKET_NAME = \"dwh-asgard\"\n",
    "    FOLDER = 'installation_point_st_partner'\n",
    "    key = f\"year={int(year)}/month={int(month)}/{int(day)}.csv\"\n",
    "    s3_file_name = f\"{FOLDER}/{key}\"\n",
    "    s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:3])\n",
    "\n",
    "    path_on_pc = 'D:/s3'\n",
    "    local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "    local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "    if os.path.isfile(local_download_path) is False:\n",
    "    # создается новая папка, если ее нет\n",
    "        os.makedirs(local_download_folder, exist_ok=True)\n",
    "        s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "    installation_point_st_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "    # Объеденяем entries_installation_points_dir_partner и installation_point_st_partner\n",
    "\n",
    "    installation_point_st_partner_df = installation_point_st_partner_df.merge(\n",
    "        entries_installation_points_dir_partner_df[['installation_point_id','address_uuid','city','country','region','parent_uuid']],\n",
    "        on='installation_point_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "\n",
    "    # Подгрузка companies_dir_partner\n",
    "\n",
    "    BUCKET_NAME = \"dwh-asgard\"\n",
    "    FOLDER = 'companies_dir_partner'\n",
    "    s3_file_name = f\"{FOLDER}/{FOLDER}.csv\"\n",
    "    s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:1])\n",
    "\n",
    "    path_on_pc = 'D:/s3'\n",
    "    local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "    local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "    if os.path.isfile(local_download_path) is False:\n",
    "    # создается новая папка, если ее нет\n",
    "        os.makedirs(local_download_folder, exist_ok=True)\n",
    "        s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "    companies_dir_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "    # Подгрузка companies_st_partner\n",
    "\n",
    "    BUCKET_NAME = \"dwh-asgard\"\n",
    "    FOLDER = 'companies_st_partner'\n",
    "    key = f\"year={int(year)}/month={int(month)}/{int(day)}.csv\"\n",
    "    s3_file_name = f\"{FOLDER}/{key}\"\n",
    "    s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:3])\n",
    "\n",
    "    path_on_pc = 'D:/s3'\n",
    "    local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "    local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "\n",
    "    if os.path.isfile(local_download_path) is False:\n",
    "    # создается новая папка, если ее нет\n",
    "        os.makedirs(local_download_folder, exist_ok=True)\n",
    "        s3.download_file(Bucket=BUCKET_NAME,Key=s3_file_name,Filename=local_download_path)\n",
    "\n",
    "    companies_st_partner_df = pd.read_csv(f'{local_download_path}')\n",
    "\n",
    "    # Объеденяем companies_st_partner и companies_dir_partner\n",
    "\n",
    "    companies_st_partner_df = companies_st_partner_df.merge(\n",
    "        companies_dir_partner_df,\n",
    "        on='partner_uuid',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Объеденяем все данные\n",
    "\n",
    "    flats_st_partner_df_merged = flats_st_partner_df.merge(\n",
    "        installation_point_st_partner_df[['digital_keys_count','device_keys_count','monetization','partner_uuid','monetization_is_allowed','installation_point_id','address_uuid','city','country','region','parent_uuid']],\n",
    "        on='address_uuid',\n",
    "        how='left'\n",
    "        )\n",
    "\n",
    "    columns = ['pro_subs','is_blocked','enterprise_subs','billing_pro','balance','company_name','partner_lk','registration_date','tin','kpp','partner_uuid']\n",
    "    flats_st_partner_df_merged = flats_st_partner_df_merged.merge(\n",
    "        companies_st_partner_df[columns],\n",
    "        on='partner_uuid',\n",
    "        how='left'\n",
    "        )\n",
    "\n",
    "    BUCKET_NAME = \"aggregated-data\"\n",
    "    FOLDER = 'flats_research_dashboard'\n",
    "\n",
    "    local_download_folder= f\"{path_on_pc}/{FOLDER}/{dates_pd.loc[i,['date_key_folder']].values[0]}\"\n",
    "    local_download_path = f\"{path_on_pc}/{FOLDER}/{dates_pd.loc[i,['date_key_parquet']].values[0]}\"\n",
    "\n",
    "    os.makedirs(local_download_folder, exist_ok=True)\n",
    "\n",
    "    flats_st_partner_df_merged.to_parquet(local_download_path, compression='snappy', index=False)\n",
    "\n",
    "    s3_file_path = f\"{FOLDER}/{dates_pd.loc[i,['date_key_parquet']].values[0]}\"\n",
    "    pc_file_path = f\"{path_on_pc}/{FOLDER}/{dates_pd.loc[i,['date_key_parquet']].values[0]}\"\n",
    "\n",
    "    s3.upload_file(pc_file_path, BUCKET_NAME, s3_file_path)\n",
    "    print(f'{s3_file_path} the file has already been uploaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
