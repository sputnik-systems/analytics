{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from config import ACCESS_KEY, SECRET_KEY, TOKEN\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "token = TOKEN\n",
    "headers={'Authorization':token,'Accept':'application/json'}\n",
    "\n",
    "#'b1gb310irjlk6b99e14g' - аналитика\n",
    "#'b1gc7vi2ckqausoc5dr7' - спутник\n",
    "\n",
    "FOLDER_ID = 'b1gc7vi2ckqausoc5dr7' # id каталога из которого береться запрос\n",
    "ACCESS_KEY = ACCESS_KEY #aws_access_key_id для S3\n",
    "SECRET_KEY = SECRET_KEY #aws_secret_access_key в s3\n",
    "\n",
    "bucket_name = 'dwh-asgard' # имя бакет\n",
    "\n",
    "#создаем подключение к yndex storage через .session.Session()\n",
    "\n",
    "def get_s3_instance():\n",
    "    session = boto3.session.Session()\n",
    "    return session.client(\n",
    "        aws_access_key_id=ACCESS_KEY,\n",
    "        aws_secret_access_key=SECRET_KEY,\n",
    "        service_name='s3',\n",
    "        endpoint_url='https://storage.yandexcloud.net'\n",
    "    )\n",
    "\n",
    "s3 = get_s3_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка ключей файлов из определенной папки\n",
    "\n",
    "Если нужно проверить целостность данных, собираемых по дням. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StartAfter позволяет сделать запрос с определенного ключа\n",
    "\n",
    "s3.list_objects_v2(Bucket=bucket_name,StartAfter = 'citizen_payments_st_mobile/year=2023/month=07/15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#код позволяет посмотеть список папок\n",
    "\n",
    "s3.list_objects_v2(Bucket=bucket_name, Delimiter='/')['CommonPrefixes'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужны все файлы, то не прописываем Prefix то Prefix=False\n",
    "def list_of_daily_objects_from_s3(bucket_name, Prefix):\n",
    "    s3 = get_s3_instance()\n",
    "    # Создаем пагинатор. Он нужен на тот случай, если файлов больше 1000\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "    # Присваеваем пагинатор с параметрами. \n",
    "    if folder is False:\n",
    "        page_iterator = paginator.paginate(Bucket=bucket_name)\n",
    "    else:    \n",
    "        page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=Prefix)\n",
    "\n",
    "    df_obj = pd.DataFrame({\n",
    "        'folder': [],\n",
    "        'year': [],\n",
    "        'month': [],\n",
    "        'day': [],\n",
    "        'key':[],\n",
    "        'LastModified':[],\n",
    "        }) # создаем пустой датасет для анализа\n",
    "\n",
    "    df_obj = df_obj.astype(str)\n",
    "\n",
    "    obj_number = 0 \n",
    "    for page in page_iterator:\n",
    "        for obj in page['Contents']: # list_objects - список объектов в бакете, Prefix - поиск во ключевому слову\n",
    "            if len(obj['Key'].split(sep='/')) == 4 \\\n",
    "            and obj['Key'].split(sep='/')[3]!='':   # условия фильтрации\n",
    "                df_obj.loc[obj_number,['folder']] = obj['Key'].split(sep='/')[0]\n",
    "                df_obj.loc[obj_number,['year']] = obj['Key'].split(sep='/')[1].replace('year=','')\n",
    "                df_obj.loc[obj_number,['month']] = obj['Key'].split(sep='/')[2].replace('month=','')\n",
    "                df_obj.loc[obj_number,['day']] = obj['Key'].split(sep='/')[3].replace('.csv','').replace('.lz4','')\n",
    "                df_obj.loc[obj_number,['key']] = obj['Key']\n",
    "                df_obj.loc[obj_number,['LastModified']] = obj['LastModified'].strftime('%Y-%m-%d %H:%M:%S',)\n",
    "            obj_number += 1 \n",
    "                # добавляем в датасет найденные значения\n",
    "                \n",
    "    df_obj['date'] = df_obj['year']+'-'+df_obj['month']+'-'+df_obj['day']\n",
    "    df_obj['date'] = pd.to_datetime(df_obj['date'], dayfirst=False)\n",
    "\n",
    "    df_obj = df_obj.reset_index().drop('index', axis=1)\n",
    "    return df_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'cameras_st_asgard' # имя папки в бакете\n",
    "Prefix = f\"{folder}/\"\n",
    "df_obj = list_of_daily_objects_from_s3(bucket_name,Prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2023</td>\n",
       "      <td>07</td>\n",
       "      <td>12</td>\n",
       "      <td>cameras_st_asgard/year=2023/month=07/12.csv</td>\n",
       "      <td>2023-07-13 10:21:20</td>\n",
       "      <td>2023-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2023</td>\n",
       "      <td>07</td>\n",
       "      <td>13</td>\n",
       "      <td>cameras_st_asgard/year=2023/month=07/13.csv</td>\n",
       "      <td>2023-07-13 23:31:55</td>\n",
       "      <td>2023-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2023</td>\n",
       "      <td>07</td>\n",
       "      <td>14</td>\n",
       "      <td>cameras_st_asgard/year=2023/month=07/14.csv</td>\n",
       "      <td>2023-07-14 23:32:17</td>\n",
       "      <td>2023-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2023</td>\n",
       "      <td>07</td>\n",
       "      <td>15</td>\n",
       "      <td>cameras_st_asgard/year=2023/month=07/15.csv</td>\n",
       "      <td>2023-07-15 23:32:04</td>\n",
       "      <td>2023-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2023</td>\n",
       "      <td>07</td>\n",
       "      <td>16</td>\n",
       "      <td>cameras_st_asgard/year=2023/month=07/16.csv</td>\n",
       "      <td>2023-07-16 23:31:57</td>\n",
       "      <td>2023-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2024</td>\n",
       "      <td>09</td>\n",
       "      <td>1</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=09/1.csv</td>\n",
       "      <td>2024-09-01 23:30:04</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2024</td>\n",
       "      <td>09</td>\n",
       "      <td>2</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=09/2.csv</td>\n",
       "      <td>2024-09-02 23:30:05</td>\n",
       "      <td>2024-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2024</td>\n",
       "      <td>09</td>\n",
       "      <td>3</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=09/3.csv</td>\n",
       "      <td>2024-09-03 23:30:05</td>\n",
       "      <td>2024-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2024</td>\n",
       "      <td>09</td>\n",
       "      <td>4</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=09/4.csv</td>\n",
       "      <td>2024-09-04 23:30:05</td>\n",
       "      <td>2024-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>cameras_st_asgard</td>\n",
       "      <td>2024</td>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=09/5.csv</td>\n",
       "      <td>2024-09-05 23:30:05</td>\n",
       "      <td>2024-09-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                folder  year month day  \\\n",
       "0    cameras_st_asgard  2023    07  12   \n",
       "1    cameras_st_asgard  2023    07  13   \n",
       "2    cameras_st_asgard  2023    07  14   \n",
       "3    cameras_st_asgard  2023    07  15   \n",
       "4    cameras_st_asgard  2023    07  16   \n",
       "..                 ...   ...   ...  ..   \n",
       "416  cameras_st_asgard  2024    09   1   \n",
       "417  cameras_st_asgard  2024    09   2   \n",
       "418  cameras_st_asgard  2024    09   3   \n",
       "419  cameras_st_asgard  2024    09   4   \n",
       "420  cameras_st_asgard  2024    09   5   \n",
       "\n",
       "                                             key         LastModified  \\\n",
       "0    cameras_st_asgard/year=2023/month=07/12.csv  2023-07-13 10:21:20   \n",
       "1    cameras_st_asgard/year=2023/month=07/13.csv  2023-07-13 23:31:55   \n",
       "2    cameras_st_asgard/year=2023/month=07/14.csv  2023-07-14 23:32:17   \n",
       "3    cameras_st_asgard/year=2023/month=07/15.csv  2023-07-15 23:32:04   \n",
       "4    cameras_st_asgard/year=2023/month=07/16.csv  2023-07-16 23:31:57   \n",
       "..                                           ...                  ...   \n",
       "416   cameras_st_asgard/year=2024/month=09/1.csv  2024-09-01 23:30:04   \n",
       "417   cameras_st_asgard/year=2024/month=09/2.csv  2024-09-02 23:30:05   \n",
       "418   cameras_st_asgard/year=2024/month=09/3.csv  2024-09-03 23:30:05   \n",
       "419   cameras_st_asgard/year=2024/month=09/4.csv  2024-09-04 23:30:05   \n",
       "420   cameras_st_asgard/year=2024/month=09/5.csv  2024-09-05 23:30:05   \n",
       "\n",
       "          date  \n",
       "0   2023-07-12  \n",
       "1   2023-07-13  \n",
       "2   2023-07-14  \n",
       "3   2023-07-15  \n",
       "4   2023-07-16  \n",
       "..         ...  \n",
       "416 2024-09-01  \n",
       "417 2024-09-02  \n",
       "418 2024-09-03  \n",
       "419 2024-09-04  \n",
       "420 2024-09-05  \n",
       "\n",
       "[421 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe пропущенных дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_missing_data(df_obj):\n",
    "    s3 = get_s3_instance()\n",
    "    # задаем стартовую и финишную дату на основе ключей\n",
    "    start_date = df_obj.loc[0,['date']].values[0]\n",
    "    end_date = df_obj.loc[df_obj.shape[0]-1,['date']].values[0]\n",
    "\n",
    "    # создаем датасет с всеми датами\n",
    "    dates_pd = pd.DataFrame({\n",
    "        'date_range': pd.date_range(start=start_date, end=end_date),\n",
    "        })\n",
    "\n",
    "    # соединяем ранее полученный список и полный список дат\n",
    "    dates_merged = dates_pd.merge(\n",
    "        df_obj,\n",
    "        left_on='date_range',\n",
    "        right_on='date',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # фильтруем полученный список по null строкам и выносим даты в отедльный датафрейм\n",
    "    df_of_missing_dates = pd.DataFrame()\n",
    "    df_of_missing_dates['date'] = dates_merged[dates_merged['key'].isnull()]['date_range'] \n",
    "    df_of_missing_dates = df_of_missing_dates.reset_index().drop('index', axis=1)\n",
    "\n",
    "    list_of_missing_dates = []\n",
    "\n",
    "    # Подставляем под пропущенные даты ключ файла, из которого будет браться информация\n",
    "    for i in range(df_of_missing_dates.shape[0]):\n",
    "\n",
    "        next_date_day = (df_of_missing_dates.loc[i,['date']] + datetime.timedelta(days=1)).iloc[0].strftime('%d')\n",
    "        next_date_month = (df_of_missing_dates.loc[i,['date']] + datetime.timedelta(days=1)).iloc[0].strftime('%m')\n",
    "        next_date_year = (df_of_missing_dates.loc[i,['date']] + datetime.timedelta(days=1)).iloc[0].strftime('%Y')\n",
    "        s3_file_name = f'{folder}/year={next_date_year}/month={next_date_month}/{int(next_date_day)}.csv'\n",
    "        try: \n",
    "            if s3.head_object(Bucket=bucket_name,Key=s3_file_name)['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "                df_of_missing_dates.loc[i,['next file key']] = s3_file_name\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # заполняем оставшиеся пропуски следующим не пустым значением\n",
    "    # эта таблица  поможет выполнить дальнейшие действия\n",
    "    df_of_missing_dates = df_of_missing_dates.bfill()\n",
    "    return df_of_missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>next file key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=08/26.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                next file key\n",
       "0 2024-08-25  cameras_st_asgard/year=2024/month=08/26.csv"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_missing_dates =  list_of_missing_data(df_obj)\n",
    "df_of_missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачивание файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В качестве ключей для скачивания используем ключи всех файлов из папки, полученные ранее\n",
    "\n",
    "def downloading_dayly_files_from_s3(path_on_pc,df_obj):\n",
    "    s3 = get_s3_instance()\n",
    "    for i in range(0,df_obj.shape[0]):\n",
    "        s3_file_name = df_obj.loc[i,['key']].values[0]\n",
    "        print(s3_file_name)\n",
    "        s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:3])\n",
    "        \n",
    "        local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "        print(local_download_folder)\n",
    "        local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "        print(local_download_path)\n",
    "        \n",
    "    # если данный файл уже скачан, он не скачивается повторно\n",
    "        if os.path.isfile(local_download_path) is False:\n",
    "        # создается новая папка, если ее нет\n",
    "            os.makedirs(local_download_folder, exist_ok=True)\n",
    "            s3.download_file(Bucket=bucket_name,Key=s3_file_name,Filename=local_download_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к основной папки на компе\n",
    "path_on_pc = 'D:/s3' \n",
    "downloading_dayly_files_from_s3(path_on_pc,df_obj)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачиваем последнее значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_file_name = df_obj.loc[df_obj.shape[0]-1,['key']].values[0]\n",
    "s3_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_file_name = df_obj.loc[df_obj.shape[0]-1,['key']].values[0]\n",
    "s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:3])\n",
    "\n",
    "local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "local_download_path = f'{path_on_pc}/{s3_file_name}'\n",
    "if os.path.isfile(local_download_path) is False:\n",
    "# создается новая папка, если ее нет\n",
    "    os.makedirs(local_download_folder, exist_ok=True)\n",
    "    s3.download_file(Bucket=bucket_name,Key=s3_file_name,Filename=local_download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачивание файлы для пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В качестве ключей для скачивания используем ключи всех файлов из папки, полученные ранее\n",
    "\n",
    "def downloading_missing_files_from_s3(path_on_pc,df_of_missing_dates):\n",
    "    s3 = get_s3_instance()\n",
    "    for i in range(0,df_of_missing_dates.shape[0]):\n",
    "        s3_file_name = df_of_missing_dates.loc[i,['next file key']].values[0]\n",
    "        s3_file_name_folder = '/'.join(s3_file_name.split(sep='/')[0:3])\n",
    "        \n",
    "        local_download_folder = f'{path_on_pc}/{s3_file_name_folder}'\n",
    "        local_download_path = f'{path_on_pc}/{s3_file_name}' \n",
    "        \n",
    "    # если данный файл уже скачан, он не скачивается повторно\n",
    "        if os.path.isfile(local_download_path) is False:\n",
    "        # создается новая папка, если ее нет\n",
    "            os.makedirs(local_download_folder, exist_ok=True)\n",
    "            s3.download_file(Bucket=bucket_name,Key=s3_file_name,Filename=local_download_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_on_pc = 'D:/s3' \n",
    "downloading_missing_files_from_s3(path_on_pc,df_of_missing_dates)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### быстро делаем резервную копию папки перед обработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/s3/entries-2024-04-19'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "src_folder = f\"{path_on_pc}/{folder}\"\n",
    "dst_folder = f\"{path_on_pc}/{folder}-{datetime.datetime.now().date().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "shutil.copytree(src_folder, dst_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проссматриваем структуру данных для понимания как дата соотносится с названием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.read_csv(f'{path_on_pc}/{df_obj.loc[0,[\"key\"]].values[0]}')\n",
    "file_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление пропущенных значений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_missing_data_to_pc(folder, path_on_pc, df_of_missing_dates):\n",
    "    # проходимся по датафрейму пропущенных значений\n",
    "    for i in range(df_of_missing_dates.shape[0]):\n",
    "        new_date = df_of_missing_dates.loc[i,[\"date\"]].values[0].strftime('%Y-%m-%d')\n",
    "        df_of_missing_dates.loc[i,[\"date\"]].values[0].strftime('year=%Y/month=%m/%#d.csv')\n",
    "        temp_df = pd.read_csv(f'{path_on_pc}/{df_of_missing_dates.loc[i,[\"next file key\"]].values[0]}')\n",
    "        # Обновляем дату\n",
    "        temp_df['report_date'] = new_date\n",
    "        temp_df.to_csv(f\"{path_on_pc}/{folder}/{df_of_missing_dates.loc[i,['date']].values[0].strftime('year=%Y/month=%m/%#d.csv')}\" ,sep=',',index=False)\n",
    "        # Создаем внутри датасета отдельный список ключей для загрузки\n",
    "        df_of_missing_dates.loc[i,['new_key']] = f\"{folder}/{df_of_missing_dates.loc[i,['date']].values[0].strftime('year=%Y/month=%m/%#d.csv')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "adding_missing_data_to_pc(folder, path_on_pc, df_of_missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>next file key</th>\n",
       "      <th>new_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=08/26.csv</td>\n",
       "      <td>cameras_st_asgard/year=2024/month=08/25.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                next file key  \\\n",
       "0 2024-08-25  cameras_st_asgard/year=2024/month=08/26.csv   \n",
       "\n",
       "                                       new_key  \n",
       "0  cameras_st_asgard/year=2024/month=08/25.csv  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upploading_missing_data_to_storage(bucket_name,path_on_pc):\n",
    "    s3 = get_s3_instance()\n",
    "    for i in range(0,df_of_missing_dates.shape[0]):\n",
    "        s3_file_path = df_of_missing_dates.loc[i,['new_key']].values[0]\n",
    "        pc_file_path = f'{path_on_pc}/{s3_file_path}'\n",
    "        try:\n",
    "            try:\n",
    "                if s3.head_object(Bucket=bucket_name,Key=s3_file_path)['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "                    print(f'{s3_file_path} the file has already been uploaded!')\n",
    "            except:\n",
    "                s3.upload_file(pc_file_path, bucket_name, s3_file_path)\n",
    "                print(f'{s3_file_path} has been uploaded')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cameras_st_asgard/year=2024/month=08/25.csv has been uploaded\n"
     ]
    }
   ],
   "source": [
    "upploading_missing_data_to_storage(bucket_name,path_on_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем\n",
    "\n",
    "list_of_missing_data(list_of_daily_objects_from_s3(bucket_name,Prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для копирования  данных из одной папки в другую внутри бакета.\n",
    "Служит а том числе вместо переименования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,dates_pd.shape[0]):\n",
    "    key = dates_pd.loc[i,['date_key']].values[0]\n",
    "    s3_file_path_old = f'entryes_st_mobile/{key}'\n",
    "    s3_file_path_new = f'entries_st_mobile/{key}'\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket_name,\n",
    "        CopySource=f'{bucket_name}/{s3_file_path_old}',\n",
    "        Key=s3_file_path_new\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
