{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "import datetime\n",
    "import os\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/boris/Documents/Work/analytics/Clickhouse')\n",
    "from clickhouse_client import ClickHouse_client\n",
    "ch = ClickHouse_client()\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ad51e",
   "metadata": {},
   "source": [
    "## Определение пустых report_date в _ch подтягивание из источников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "class ClickHouse_client:\n",
    "    def __init__(self):\n",
    "        self.client = clickhouse_connect.get_client(host='rc1a-eflrt968scbm232q.mdb.yandexcloud.net', \n",
    "                                    port=8443, \n",
    "                                    username='Boris', \n",
    "                                    password=PASSWORD, \n",
    "                                    secure=True,\n",
    "                                    verify=False,\n",
    "                                    database='db1')\n",
    "\n",
    "    def query_run (self, query_text):\n",
    "        query_text = query_text\n",
    "        result = self.client.query(query_text)\n",
    "        self.df = pd.DataFrame(result.result_rows, columns=result.column_names)\n",
    "        # self.df = pl.DataFrame(result.result_rows, schema=result.column_names)\n",
    "        # self.df =  pl.from_pandas(self.df)\n",
    "        # display(self.df)\n",
    "        return self.df\n",
    "\n",
    "ch = ClickHouse_client()\n",
    "\n",
    "def insert_new_date(table, special=False):\n",
    "    query_text = f\"\"\"\n",
    "        SELECT source.report_date AS report_date\n",
    "        FROM (SELECT DISTINCT report_date FROM `{table}_mv_df`) AS source\n",
    "        LEFT ANTI JOIN\n",
    "        (\n",
    "            SELECT DISTINCT report_date\n",
    "            FROM `{table}_ch`\n",
    "        ) ch USING (report_date)\n",
    "        ORDER BY source.report_date\n",
    "    \"\"\"\n",
    "\n",
    "    df = ch.query_run(query_text)      # df: pandas.DataFrame\n",
    "    missing = df['report_date'].tolist() if not df.empty else []\n",
    "    dates_pd = pd.DataFrame({\n",
    "            'report_date': [d.strftime('%Y-%m-%d') for d in missing],\n",
    "            'date_key_1': [d.strftime('%%/year=%-Y/month=%m/%d%%') for d in missing], \n",
    "            'date_key_2': [d.strftime('%%/year=%-Y/month=%-m/%d%%') for d in missing], \n",
    "            'date_key_3': [d.strftime('%%/year=%-Y/month=%-m/%-d%%') for d in missing],\n",
    "            'date_key_4': [d.strftime('%%/year=%-Y/month=%m/%-d%%') for d in missing],  \n",
    "            })\n",
    "    dates_pd = dates_pd.iloc[::-1].reset_index(drop=True)\n",
    "    \n",
    "    if special:\n",
    "        for day_index in dates_pd.index:\n",
    "            report_date = dates_pd.loc[day_index,['report_date']].values[0]\n",
    "            date_key_1 = dates_pd.loc[day_index,['date_key_1']].values[0]\n",
    "            date_key_2 = dates_pd.loc[day_index,['date_key_2']].values[0]\n",
    "            date_key_3 = dates_pd.loc[day_index,['date_key_3']].values[0]\n",
    "            date_key_4 = dates_pd.loc[day_index,['date_key_4']].values[0]\n",
    "            query_text = open(f'{table}_ch.txt','r').read().format(report_date,date_key_1,date_key_2,date_key_3,date_key_4)\n",
    "            # приведём к литералу ClickHouse (подберите нужный тип)\n",
    "            ch.query_run(query_text)\n",
    "    else:\n",
    "        for day_index in dates_pd.index:\n",
    "            report_date = dates_pd.loc[day_index,['report_date']].values[0]\n",
    "            date_key_1 = dates_pd.loc[day_index,['date_key_1']].values[0]\n",
    "            date_key_2 = dates_pd.loc[day_index,['date_key_2']].values[0]\n",
    "            date_key_3 = dates_pd.loc[day_index,['date_key_3']].values[0]\n",
    "            date_key_4 = dates_pd.loc[day_index,['date_key_4']].values[0]\n",
    "            query_text = open(f'regular_query.txt','r').read().format(report_date,date_key_1,date_key_2,date_key_3,date_key_4,table)\n",
    "            # приведём к литералу ClickHouse (подберите нужный тип)\n",
    "            ch.query_run(query_text)\n",
    "\n",
    "\n",
    "tables_list_spacial = ['citizens_st_mobile','companies_st_partner','intercoms_st_asgard']\n",
    "\n",
    "tables_list = ch.query_run('SHOW TABLES')\n",
    "tables_list = tables_list['name'].to_list()\n",
    "filtered_tables = [\n",
    "    t for t in tables_list\n",
    "    if ('_st_' in t \n",
    "            or 'hex_metrics_parquet' in t\n",
    "            or 'metrics_all_intercoms_asgard' in t\n",
    "            or 'metrics_asgard' in t\n",
    "        ) \n",
    "        and not (t.endswith('_ch') \n",
    "                or t.endswith('_mv') \n",
    "                or t.endswith('_df') \n",
    "                or t.startswith('t_') \n",
    "                or t.endswith('_data')\n",
    "                or t.endswith('_ch_2')\n",
    "                or t.endswith('_mv_2'))\n",
    "        and t not in tables_list_spacial\n",
    "]\n",
    "\n",
    "def handler(event, context):\n",
    "    for table in tables_list_spacial:\n",
    "        insert_new_date(table,special=True)\n",
    "\n",
    "    for table in filtered_tables:\n",
    "        insert_new_date(table,special=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca84b0",
   "metadata": {},
   "source": [
    "## Создание MV с подсчетом значений по дням для таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b65420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_type(t: str) -> str:\n",
    "    \"\"\"\n",
    "    Убираем внешние обёртки типа: Nullable(...), LowCardinality(...),\n",
    "    SimpleAggregateFunction(..., T) и т.п., чтобы получить базовый тип.\n",
    "    \"\"\"\n",
    "    tl = t.strip()\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for prefix in ('Nullable(', 'LowCardinality(', 'SimpleAggregateFunction('):\n",
    "            if tl.startswith(prefix):\n",
    "                # SimpleAggregateFunction(ARG,..., T) -> берём последнюю запятую как разделитель T\n",
    "                if prefix == 'SimpleAggregateFunction(':\n",
    "                    inner = tl[len(prefix):-1]  # без последней \")\"\n",
    "                    # тип — после последней запятой\n",
    "                    if ',' in inner:\n",
    "                        tl = inner.split(',')[-1].strip()\n",
    "                        changed = True\n",
    "                        break\n",
    "                else:\n",
    "                    # Общий случай: тип внутри скобок\n",
    "                    tl = tl[len(prefix):-1].strip()\n",
    "                    changed = True\n",
    "                    break\n",
    "    return tl\n",
    "\n",
    "def needs_notnull_guard(t: str) -> bool:\n",
    "    return t.strip().startswith('Nullable(')\n",
    "\n",
    "def cond_for_type(col_expr: str, full_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Возвращает булево условие \"значение задано/не по умолчанию\" для столбца col_expr.\n",
    "    \"\"\"\n",
    "    base = unwrap_type(full_type).lower()\n",
    "\n",
    "    # Числа: Int*, UInt*, Float*, Decimal*\n",
    "    if (base.startswith('int') or base.startswith('uint') or\n",
    "        base.startswith('float') or base.startswith('decimal')):\n",
    "        cond = f\"{col_expr} != 0\"\n",
    "        if base.startswith('float'):\n",
    "            # На всякий случай исключим NaN/Inf\n",
    "            cond = f\"({cond} AND isFinite({col_expr}) AND NOT isNaN({col_expr}))\"\n",
    "        return cond\n",
    "\n",
    "    # Строки: String, FixedString(N)\n",
    "    if base == 'string' or base.startswith('fixedstring'):\n",
    "        return f\"notEmpty({col_expr})\"\n",
    "\n",
    "    # LowCardinality(String) уже развёрнут выше до string, но на всякий случай:\n",
    "    if base.startswith('lowcardinality('):\n",
    "        return f\"notEmpty({col_expr})\"\n",
    "\n",
    "    # Даты/время: Date, Date32, DateTime, DateTime64\n",
    "    if base == 'date' or base == 'date32' or base.startswith('datetime'):\n",
    "        # Приводим к UInt32: epoch-дни/секунды будут 0 для дефолта '1970-01-01'\n",
    "        return f\"toUInt32({col_expr}) != 0\"\n",
    "\n",
    "    # UUID\n",
    "    if base == 'uuid':\n",
    "        return f\"{col_expr} != toUUID('00000000-0000-0000-0000-000000000000')\"\n",
    "\n",
    "    # IP\n",
    "    if base == 'ipv4':\n",
    "        return f\"{col_expr} != toIPv4(0)\"\n",
    "    if base == 'ipv6':\n",
    "        return f\"{col_expr} != toIPv6('::')\"\n",
    "\n",
    "    # Enum\n",
    "    if base.startswith('enum8') or base.startswith('enum16'):\n",
    "        return f\"toInt64({col_expr}) != 0\"\n",
    "\n",
    "    # Контейнеры: Array, Map, Tuple, Nested\n",
    "    if base.startswith('array(') or base.startswith('map(') or base.startswith('tuple(') or base.startswith('nested('):\n",
    "        return f\"notEmpty({col_expr})\"\n",
    "\n",
    "    # Прочие сложные/экзотические типы (Object('JSON'), Variant и т.п.) — считаем «не NULL»\n",
    "    return f\"isNotNull({col_expr})\"\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "tables = ch.query_run('SHOW TABLES')['name'].to_list()\n",
    "\n",
    "filtered_tables = [\n",
    "    t for t in tables\n",
    "    if (t.startswith('t_') \n",
    "        or 'maf_rep_mobile_total' in t\n",
    "        or 'mobile_report_cum_rep_mobile_full' in t\n",
    "        or 'mobile_report_rep_mobile_full' in t\n",
    "        or 'mobile_report_total' in t\n",
    "        or 'new_users_pd_rep_mobile_total' in t\n",
    "        or 'rep_mobile_citizens_id_city_partner' in t\n",
    "        or 'subscriptions_report_citizens_flats_comerce_rep_mobile_total' in t\n",
    "        or 'subscriptions_report_comerce_rep_mobile_total' in t\n",
    "        or 'total_active_users_per_day_full_table' in t\n",
    "        or 'total_active_users_per_day_rep_mobile_total' in t\n",
    "        or 'total_active_users_rep_mobile_total' in t\n",
    "        or 'units_on_sk_platform_rep_mobile_total' in t\n",
    "        ) \n",
    "        and not (t.endswith('_ch') \n",
    "                or t.endswith('_mv') \n",
    "                or t.endswith('_df') \n",
    "                or t.endswith('_mv_cod')\n",
    "                or 't_bitrix_deals_sales' in t\n",
    "                )\n",
    "]\n",
    "\n",
    "filtered_tables_mv_cod = [\n",
    "    t for t in tables\n",
    "    if t.endswith('_mv_cod')\n",
    "]\n",
    "\n",
    "for table in filtered_tables:\n",
    "    mv_table = f\"{table}_mv_cod\"\n",
    "    if mv_table in filtered_tables_mv_cod:\n",
    "        query_text = f\"\"\"\n",
    "        SYSTEM REFRESH VIEW {mv_table}\n",
    "        \"\"\"\n",
    "        ch.query_run(query_text)\n",
    "    else:\n",
    "        cols = ch.get_schema_dict(f'SELECT * FROM {table} LIMIT 1')  # список кортежей (name, type)\n",
    "        conds = []\n",
    "        for col, ctype in cols:\n",
    "            if col == 'report_date':\n",
    "                continue\n",
    "            col_expr = f\"t.`{col}` = 0\"\n",
    "            conds.append(col_expr)\n",
    "\n",
    "        where_clause = ' OR '.join(conds)\n",
    "\n",
    "        group_cols = []\n",
    "        for col, ctype in cols:\n",
    "            col_quoted = f\"`{col}`\"\n",
    "\n",
    "            if col == 'report_date':\n",
    "                group_cols.append(col_quoted)\n",
    "                continue\n",
    "\n",
    "            base_condition = cond_for_type(col_quoted, ctype)\n",
    "\n",
    "            # Если столбец Nullable — добавим явную проверку на не-NULL\n",
    "            if needs_notnull_guard(ctype):\n",
    "                condition = f\"(isNotNull({col_quoted}) AND {base_condition})\"\n",
    "            else:\n",
    "                condition = base_condition\n",
    "\n",
    "            group_cols.append(f\"countIf({condition}) AS `{col}`\")\n",
    "\n",
    "        select_clause = ', '.join(group_cols)\n",
    "\n",
    "        query_text = f\"\"\"\n",
    "        CREATE MATERIALIZED VIEW {mv_table}\n",
    "        REFRESH EVERY 1 DAY OFFSET 4 HOUR 30 MINUTE RANDOMIZE FOR 10 MINUTE\n",
    "        ENGINE = AggregatingMergeTree()\n",
    "        ORDER BY report_date\n",
    "        AS\n",
    "        SELECT\n",
    "            d.date AS report_date,\n",
    "            t.* EXCEPT report_date\n",
    "        FROM db1.date_range_mv AS d\n",
    "        LEFT JOIN (\n",
    "            SELECT\n",
    "                {select_clause}\n",
    "            FROM {table}\n",
    "            GROUP BY report_date\n",
    "        ) AS t\n",
    "            ON d.date = t.report_date\n",
    "        ORDER BY d.date DESC\n",
    "        SETTINGS input_format_parallel_parsing = 0,\n",
    "            date_time_input_format = 'best_effort'\n",
    "        \"\"\"\n",
    "\n",
    "        print(query_text)\n",
    "        print(mv_table)\n",
    "        ch.query_run(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7616071",
   "metadata": {},
   "source": [
    "## Графики всех таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotly pandas\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "DATE_COL = \"report_date\"\n",
    "LABEL_FONT_SIZE = 14\n",
    "LABEL_XSHIFT = -6\n",
    "\n",
    "tables = ch.query_run(\"SHOW TABLES\")[\"name\"].to_list()\n",
    "tables = [t for t in tables if t.endswith(\"_mv_cod\")]\n",
    "\n",
    "for table in tables:\n",
    "    schema = ch.get_schema_dict(f\"SELECT * FROM {table} LIMIT 1\")\n",
    "    cols = [name for name, _ in schema]\n",
    "    if DATE_COL not in cols:\n",
    "        continue\n",
    "    y_cols = [c for c in cols if c != DATE_COL]\n",
    "    if not y_cols:\n",
    "        continue\n",
    "\n",
    "    select_cols = \", \".join(f\"`{c}`\" for c in [DATE_COL] + y_cols)\n",
    "    df = ch.query_run(f\"SELECT {select_cols} FROM {table} ORDER BY {DATE_COL}\")\n",
    "    if df.empty:\n",
    "        continue\n",
    "    if df[DATE_COL].dtype == object:\n",
    "        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "    rows = len(y_cols)\n",
    "    fig = make_subplots(rows=rows, cols=1, shared_xaxes=True, vertical_spacing=0.0)\n",
    "\n",
    "    for i, col in enumerate(y_cols, start=1):\n",
    "        # линия\n",
    "        fig.add_trace(go.Scatter(x=df[DATE_COL], y=df[col], mode=\"lines\", name=col),\n",
    "                      row=i, col=1)\n",
    "\n",
    "        # подпись у первой непустой точки\n",
    "        s = df[[DATE_COL, col]].dropna()\n",
    "        if not s.empty:\n",
    "            fig.add_annotation(x=s[DATE_COL].iloc[0], y=s[col].iloc[0],\n",
    "                               xref=f\"x{i}\", yref=f\"y{i}\",\n",
    "                               text=col, showarrow=False,\n",
    "                               xanchor=\"right\", xshift=LABEL_XSHIFT,\n",
    "                               font=dict(size=LABEL_FONT_SIZE))\n",
    "\n",
    "        # <<< нулевая линия\n",
    "        fig.add_shape(type=\"line\",\n",
    "                      xref=f\"x{i}\", yref=f\"y{i}\",\n",
    "                      x0=df[DATE_COL].min(), x1=df[DATE_COL].max(),\n",
    "                      y0=0, y1=0,\n",
    "                      line=dict(color=\"black\", width=3),\n",
    "                      layer=\"below\")\n",
    "\n",
    "        # <<< гарантируем, что 0 попадёт в диапазон\n",
    "        fig.update_yaxes(rangemode=\"tozero\", row=i, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(text=table, font=dict(size=28)),\n",
    "        height=max(280, 95 * rows),\n",
    "        showlegend=False,\n",
    "        margin=dict(l=50, r=30, t=60, b=30)\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd156316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install clickhouse-connect\n",
    "import clickhouse_connect\n",
    "\n",
    "def build_empty_sql(db, table, date_col='report_date', wide=False):\n",
    "    cols = ch.query_run(f\"\"\"\n",
    "        SELECT name, type\n",
    "        FROM system.columns\n",
    "        WHERE database = %(db)s AND table = %(table)s\n",
    "        ORDER BY position\n",
    "    \"\"\", parameters={'db': db, 'table': table}).result_rows\n",
    "\n",
    "    def skip(t: str) -> bool:\n",
    "      t = t.lower()\n",
    "      return t.startswith(('array(', 'map(', 'aggregatefunction('))\n",
    "\n",
    "    def empty_expr(col, t):\n",
    "        colq, tlo = f'`{col}`', t.lower()\n",
    "\n",
    "        def base(x):\n",
    "            if 'string' in tlo:                          return f\"{x} = ''\"\n",
    "            if tlo.startswith('date(') or tlo == 'date': return f\"{x} = toDate(0)\"\n",
    "            if 'datetime' in tlo:                        return f\"{x} = toDateTime(0)\"\n",
    "            if 'float' in tlo:                           return f\"(({x} = 0) OR isNaN({x}))\"\n",
    "            if any(k in tlo for k in ('int', 'uint','decimal')): return f\"{x} = 0\"\n",
    "            return \"0\"\n",
    "\n",
    "        if 'nullable(' in tlo:\n",
    "            return f\"(isNull({colq}) OR {base(f'assumeNotNull({colq})')})\"\n",
    "        return base(colq)\n",
    "\n",
    "    targets = [(c, t) for c, t in cols if c != date_col and not skip(t)]\n",
    "    if not targets:\n",
    "        raise ValueError(\"Нет подходящих колонок для подсчёта.\")\n",
    "\n",
    "    if not wide:\n",
    "        keys = \", \".join(f\"'{c}'\" for c, _ in targets)\n",
    "        vals = \", \".join(f\"({empty_expr(c, t)})::UInt64\" for c, t in targets)\n",
    "        return f\"\"\"\n",
    "/* tidy: report_date | column | empty_count */\n",
    "SELECT\n",
    "  {date_col} AS report_date,\n",
    "  arrayJoin(keys)   AS column,\n",
    "  arrayJoin(values) AS empty_count\n",
    "FROM (\n",
    "  SELECT {date_col}, sumMap(keys, vals) AS (keys, values)\n",
    "  FROM (\n",
    "    SELECT\n",
    "      {date_col},\n",
    "      [{keys}] AS keys,\n",
    "      [{vals}] AS vals\n",
    "    FROM `{db}`.`{table}`\n",
    "  )\n",
    "  GROUP BY {date_col}\n",
    ")\n",
    "ORDER BY report_date, column\n",
    "\"\"\".strip()\n",
    "\n",
    "    # wide\n",
    "    aggs = \",\\n  \".join(\n",
    "        f\"sum(({empty_expr(c, t)})::UInt64) AS empty_{c}\" for c, t in targets\n",
    "    )\n",
    "    return f\"\"\"\n",
    "/* wide: report_date + empty_<column>... */\n",
    "SELECT\n",
    "  {date_col},\n",
    "  {aggs}\n",
    "FROM `{db}`.`{table}`\n",
    "GROUP BY {date_col}\n",
    "ORDER BY {date_col}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a213c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_empty_counts_wide_sql('db1','cameras_dir_asgard_ch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f349e",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278500a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  report_date\n",
      "0  2025-09-15\n",
      "1  2025-09-14\n",
      "2  2025-08-11\n",
      "3  2024-08-04\n",
      "4  2024-08-03\n"
     ]
    }
   ],
   "source": [
    "def insert_new_date(table, special=False):\n",
    "    query_text = f\"\"\"\n",
    "        SELECT date_range_mv.report_date AS report_date\n",
    "        FROM (SELECT DISTINCT date AS report_date FROM `date_range_mv`) AS date_range_mv\n",
    "        LEFT ANTI JOIN\n",
    "        (\n",
    "            SELECT DISTINCT report_date\n",
    "            FROM `{table}`\n",
    "        ) ch USING (report_date)\n",
    "        ORDER BY date_range_mv.report_date\n",
    "    \"\"\"\n",
    "\n",
    "    df = ch.query_run(query_text)      # df: pandas.DataFrame\n",
    "    missing = df['report_date'].tolist() if not df.empty else []\n",
    "    dates_pd = pd.DataFrame({\n",
    "            'report_date': [d.strftime('%Y-%m-%d') for d in missing]\n",
    "            })\n",
    "    dates_pd = dates_pd.iloc[::-1].reset_index(drop=True)\n",
    "    for day_index in dates_pd.index:\n",
    "        report_date = dates_pd.loc[day_index,['report_date']].values[0]\n",
    "        query_text = open(f'{table}.txt','r').read().format(report_date)\n",
    "        # приведём к литералу ClickHouse (подберите нужный тип)\n",
    "        print(report_date)\n",
    "        ch.query_run(query_text)\n",
    "    \n",
    "tables_list= ['total_active_users_per_day_full_table']\n",
    "for table in tables_list:\n",
    "    insert_new_date(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
